"""
myparser/integrated_ai_parser.py - –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AI –ø–∞—Ä—Å–µ—Ä
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ –∏ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
"""

import asyncio
import logging
import json
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass, asdict
from telegram import Update, User
from telegram.ext import ContextTypes

from database.operations import create_lead, update_channel_stats
from database.models import Lead
from ai.claude_client import get_claude_client

logger = logging.getLogger(__name__)

@dataclass
class UserContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    user_id: int
    username: Optional[str]
    first_name: Optional[str]
    last_name: Optional[str]
    messages: List[Dict[str, Any]]
    first_seen: datetime
    last_activity: datetime
    channel_info: Dict[str, Any]

@dataclass
class AIAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç AI –∞–Ω–∞–ª–∏–∑–∞"""
    is_lead: bool
    confidence_score: int
    lead_quality: str
    interests: List[str]
    buying_signals: List[str]
    urgency_level: str
    recommended_action: str
    key_insights: List[str]
    estimated_budget: Optional[str]
    timeline: Optional[str]
    pain_points: List[str]
    decision_stage: str

@dataclass
class DialogueParticipant:
    """–£—á–∞—Å—Ç–Ω–∏–∫ –¥–∏–∞–ª–æ–≥–∞"""
    user_id: int
    username: Optional[str]
    first_name: Optional[str]
    last_name: Optional[str]
    role: str = "participant"
    message_count: int = 0
    first_message_time: Optional[datetime] = None
    last_message_time: Optional[datetime] = None
    engagement_level: str = "low"
    buying_signals_count: int = 0
    influence_score: int = 0

@dataclass
class DialogueMessage:
    """–°–æ–æ–±—â–µ–Ω–∏–µ –≤ –¥–∏–∞–ª–æ–≥–µ"""
    user_id: int
    username: Optional[str]
    text: str
    timestamp: datetime
    message_id: int
    reply_to_message_id: Optional[int] = None
    reply_to_user_id: Optional[int] = None
    buying_signals: List[str] = None
    sentiment: str = "neutral"
    urgency_level: str = "none"

@dataclass
class DialogueContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞"""
    dialogue_id: str
    channel_id: int
    channel_title: str
    participants: Dict[int, DialogueParticipant]
    messages: List[DialogueMessage]
    start_time: datetime
    last_activity: datetime
    topic: Optional[str] = None
    dialogue_type: str = "discussion"
    is_business_related: bool = False
    overall_sentiment: str = "neutral"
    decision_stage: str = "awareness"
    group_buying_probability: float = 0.0

@dataclass
class DialogueAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞"""
    dialogue_id: str
    is_valuable_dialogue: bool
    confidence_score: int
    potential_leads: List[Dict[str, Any]]
    group_dynamics: Dict[str, Any]
    business_relevance_score: int
    recommended_actions: List[str]
    key_insights: List[str]
    dialogue_summary: str
    participant_analysis: Dict[int, Dict[str, Any]]
    buying_probability: Dict[str, float]
    influence_map: Dict[int, List[int]]
    next_best_action: str
    estimated_timeline: Optional[str]
    group_budget_estimate: Optional[str]

class DialogueTracker:
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞–º–∏"""
    
    def __init__(self, config):
        self.config = config
        self.active_dialogues: Dict[str, DialogueContext] = {}
        self.dialogue_timeout = timedelta(minutes=15)
        self.min_participants = 2
        self.min_messages = 3
        self.reply_window = timedelta(minutes=5)
        self.max_dialogue_duration = timedelta(hours=2)
        
        logger.info("DialogueTracker –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def get_dialogue_id(self, channel_id: int, start_time: datetime) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID –¥–∏–∞–ª–æ–≥–∞"""
        return f"dialogue_{channel_id}_{start_time.strftime('%Y%m%d_%H%M%S')}"

    async def process_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> Optional[str]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ –¥–∏–∞–ª–æ–≥—É"""
        try:
            chat_id = update.effective_chat.id
            user = update.effective_user
            message = update.message
            
            if not user or not message or not message.text:
                return None
            
            await self._cleanup_expired_dialogues()
            active_dialogue = self._find_active_dialogue(chat_id)
            is_dialogue_message = self._is_dialogue_message(message, active_dialogue)
            
            if is_dialogue_message and active_dialogue:
                await self._add_message_to_dialogue(active_dialogue, user, message)
                logger.info(f"üìù –°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ –¥–∏–∞–ª–æ–≥—É {active_dialogue.dialogue_id}")
                return active_dialogue.dialogue_id
            elif self._should_start_new_dialogue(chat_id, user, message):
                new_dialogue = await self._start_new_dialogue(chat_id, update.effective_chat.title, user, message)
                logger.info(f"üÜï –ù–∞—á–∞—Ç –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥: {new_dialogue.dialogue_id}")
                return new_dialogue.dialogue_id
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –¥–∏–∞–ª–æ–≥–∞: {e}")
            return None

    def _find_active_dialogue(self, channel_id: int) -> Optional[DialogueContext]:
        """–ü–æ–∏—Å–∫ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –≤ –∫–∞–Ω–∞–ª–µ"""
        for dialogue in self.active_dialogues.values():
            if (dialogue.channel_id == channel_id and 
                datetime.now() - dialogue.last_activity < self.dialogue_timeout):
                return dialogue
        return None

    def _is_dialogue_message(self, message, active_dialogue: Optional[DialogueContext]) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —á–∞—Å—Ç—å—é –¥–∏–∞–ª–æ–≥–∞"""
        if not active_dialogue:
            return False
        
        time_diff = datetime.now() - active_dialogue.last_activity
        if time_diff > self.dialogue_timeout:
            return False
        
        if message.reply_to_message:
            reply_user_id = message.reply_to_message.from_user.id
            if reply_user_id in active_dialogue.participants:
                return True
        
        if message.from_user.id in active_dialogue.participants:
            return True
        
        return self._has_contextual_connection(message, active_dialogue)

    def _has_contextual_connection(self, message, dialogue: DialogueContext) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π —Å–≤—è–∑–∏ —Å –¥–∏–∞–ª–æ–≥–æ–º"""
        message_text = message.text.lower()
        
        for participant in dialogue.participants.values():
            if participant.username and f"@{participant.username.lower()}" in message_text:
                return True
        
        if dialogue.is_business_related:
            business_keywords = ['crm', '–±–æ—Ç', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è', '—Å–∏—Å—Ç–µ–º–∞', '–∑–∞–∫–∞–∑', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å']
            if any(keyword in message_text for keyword in business_keywords):
                return True
        
        return False

    def _should_start_new_dialogue(self, channel_id: int, user: User, message) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω—É–∂–Ω–æ –ª–∏ –Ω–∞—á–∏–Ω–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥"""
        if message.reply_to_message and message.reply_to_message.from_user.id != user.id:
            return True
        
        if self._contains_question_patterns(message.text):
            return True
        
        if self._contains_business_signals(message.text):
            return True
        
        return False

    def _contains_question_patterns(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        question_patterns = [
            '?', '–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–∫—Ç–æ',
            '–º–æ–∂–µ—Ç–µ –ª–∏', '–≤–æ–∑–º–æ–∂–Ω–æ –ª–∏', '–∞ —á—Ç–æ –µ—Å–ª–∏', '–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ', '–ø–æ–º–æ–≥–∏—Ç–µ'
        ]
        text_lower = text.lower()
        return any(pattern in text_lower for pattern in question_patterns)

    def _contains_business_signals(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–µ–ª–æ–≤—ã–µ/–ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã"""
        business_signals = [
            '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '–∫—É–ø–∏—Ç—å', '–∑–∞–∫–∞–∑–∞—Ç—å', 'crm', '–±–æ—Ç', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è',
            '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', '–Ω—É–∂–Ω–æ', '—Ç—Ä–µ–±—É–µ—Ç—Å—è', '–∏—â—É', '–∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç', '—Ö–æ—á—É —É–∑–Ω–∞—Ç—å'
        ]
        text_lower = text.lower()
        return any(signal in text_lower for signal in business_signals)

    async def _start_new_dialogue(self, channel_id: int, channel_title: str, 
                                user: User, message) -> DialogueContext:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞"""
        start_time = datetime.now()
        dialogue_id = self.get_dialogue_id(channel_id, start_time)
        
        participant = DialogueParticipant(
            user_id=user.id,
            username=user.username,
            first_name=user.first_name,
            last_name=user.last_name,
            role="initiator",
            message_count=1,
            first_message_time=start_time,
            last_message_time=start_time
        )
        
        dialogue = DialogueContext(
            dialogue_id=dialogue_id,
            channel_id=channel_id,
            channel_title=channel_title or f"Channel_{channel_id}",
            participants={user.id: participant},
            messages=[],
            start_time=start_time,
            last_activity=start_time,
            is_business_related=self._contains_business_signals(message.text)
        )
        
        await self._add_message_to_dialogue(dialogue, user, message)
        self.active_dialogues[dialogue_id] = dialogue
        return dialogue

    async def _add_message_to_dialogue(self, dialogue: DialogueContext, user: User, message):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫ –¥–∏–∞–ª–æ–≥—É"""
        current_time = datetime.now()
        
        if user.id not in dialogue.participants:
            role = "responder" if len(dialogue.participants) == 1 else "participant"
            participant = DialogueParticipant(
                user_id=user.id,
                username=user.username,
                first_name=user.first_name,
                last_name=user.last_name,
                role=role,
                message_count=1,
                first_message_time=current_time,
                last_message_time=current_time
            )
            dialogue.participants[user.id] = participant
        else:
            participant = dialogue.participants[user.id]
            participant.message_count += 1
            participant.last_message_time = current_time
        
        buying_signals = self._extract_buying_signals(message.text)
        if buying_signals:
            participant.buying_signals_count += len(buying_signals)
        
        dialogue_message = DialogueMessage(
            user_id=user.id,
            username=user.username,
            text=message.text,
            timestamp=current_time,
            message_id=message.message_id,
            reply_to_message_id=message.reply_to_message.message_id if message.reply_to_message else None,
            reply_to_user_id=message.reply_to_message.from_user.id if message.reply_to_message else None,
            buying_signals=buying_signals,
            sentiment=self._analyze_sentiment(message.text),
            urgency_level=self._detect_urgency(message.text)
        )
        
        dialogue.messages.append(dialogue_message)
        dialogue.last_activity = current_time
        
        if buying_signals or self._contains_business_signals(message.text):
            dialogue.is_business_related = True

    def _extract_buying_signals(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        signals = []
        text_lower = text.lower()
        
        signal_patterns = {
            'price_inquiry': ['—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç', '–ø—Ä–∞–π—Å'],
            'purchase_intent': ['–∫—É–ø–∏—Ç—å', '–∑–∞–∫–∞–∑–∞—Ç—å', '—Ö–æ—á—É –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏', '–≥–æ—Ç–æ–≤ –∫—É–ø–∏—Ç—å'],
            'urgency': ['—Å—Ä–æ—á–Ω–æ', '–±—ã—Å—Ç—Ä–æ', '—Å–µ–≥–æ–¥–Ω—è', '—Å–µ–π—á–∞—Å', '–∫–∞–∫ –º–æ–∂–Ω–æ —Å–∫–æ—Ä–µ–µ'],
            'budget_discussion': ['–±—é–¥–∂–µ—Ç', '–≥–æ—Ç–æ–≤ –ø–æ—Ç—Ä–∞—Ç–∏—Ç—å', '—Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é –Ω–∞'],
            'decision_making': ['—Ä–µ—à–µ–Ω–∏–µ', '–≤—ã–±–∏—Ä–∞—é', '—Å—Ä–∞–≤–Ω–∏–≤–∞—é', '–¥—É–º–∞—é –Ω–∞–¥'],
            'timeline': ['–∫–æ–≥–¥–∞', '—Å—Ä–æ–∫–∏', '–¥–æ –∫–∞–∫–æ–≥–æ —á–∏—Å–ª–∞', '–≤ —Ç–µ—á–µ–Ω–∏–µ']
        }
        
        for category, patterns in signal_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    signals.append(f"{category}: {pattern}")
        
        return signals

    def _analyze_sentiment(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        positive_words = ['—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ', '–ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å', '—Å–æ–≥–ª–∞—Å–µ–Ω', '–¥–∞', '—Å–ø–∞—Å–∏–±–æ', '–∑–¥–æ—Ä–æ–≤–æ']
        negative_words = ['–ø–ª–æ—Ö–æ', '–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è', '–¥–æ—Ä–æ–≥–æ', '–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç', '–Ω–µ—Ç', '–æ—Ç–∫–∞–∑—ã–≤–∞—é—Å—å']
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"

    def _detect_urgency(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å—Ä–æ—á–Ω–æ—Å—Ç–∏"""
        text_lower = text.lower()
        
        if any(word in text_lower for word in ['—Å—Ä–æ—á–Ω–æ', '—Å–µ–π—á–∞—Å', '–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ']):
            return "immediate"
        elif any(word in text_lower for word in ['–±—ã—Å—Ç—Ä–æ', '—Å–µ–≥–æ–¥–Ω—è', '–∑–∞–≤—Ç—Ä–∞']):
            return "high"
        elif any(word in text_lower for word in ['–Ω–∞ –¥–Ω—è—Ö', '–Ω–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ', '—Å–∫–æ—Ä–æ']):
            return "medium"
        elif any(word in text_lower for word in ['–≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ', '–∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å', '–º–æ–∂–µ—Ç –±—ã—Ç—å']):
            return "low"
        else:
            return "none"

    async def _cleanup_expired_dialogues(self):
        """–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤"""
        current_time = datetime.now()
        expired_dialogues = []
        
        for dialogue_id, dialogue in self.active_dialogues.items():
            if (current_time - dialogue.last_activity > self.dialogue_timeout or
                current_time - dialogue.start_time > self.max_dialogue_duration):
                expired_dialogues.append(dialogue_id)
        
        for dialogue_id in expired_dialogues:
            completed_dialogue = self.active_dialogues.pop(dialogue_id)
            logger.info(f"üèÅ –î–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {dialogue_id} ({len(completed_dialogue.messages)} —Å–æ–æ–±—â–µ–Ω–∏–π)")

    def get_completed_dialogues_for_analysis(self) -> List[DialogueContext]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –≥–æ—Ç–æ–≤—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        current_time = datetime.now()
        completed = []
        
        for dialogue in self.active_dialogues.values():
            if (len(dialogue.participants) >= self.min_participants and
                len(dialogue.messages) >= self.min_messages and
                current_time - dialogue.last_activity > timedelta(minutes=5)):
                completed.append(dialogue)
        
        return completed

class DialogueAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤ —Å –ø–æ–º–æ—â—å—é AI"""
    
    def __init__(self, config):
        self.config = config
        self.claude_client = get_claude_client()
        logger.info("DialogueAnalyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    async def analyze_dialogue(self, dialogue: DialogueContext) -> Optional[DialogueAnalysisResult]:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞"""
        try:
            logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ {dialogue.dialogue_id}")
            
            if not self.claude_client or not self.claude_client.client:
                logger.warning("Claude API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                return self._simple_dialogue_analysis(dialogue)
            
            analysis_prompt = self._create_dialogue_analysis_prompt(dialogue)
            
            response = await asyncio.wait_for(
                self.claude_client.client.messages.create(
                    model=self.claude_client.model,
                    max_tokens=3000,
                    messages=[{"role": "user", "content": analysis_prompt}],
                    temperature=0.1
                ),
                timeout=20.0
            )
            
            analysis_result = self._parse_dialogue_analysis_response(response.content[0].text, dialogue)
            
            logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ –∑–∞–≤–µ—Ä—à–µ–Ω: —Ü–µ–Ω–Ω–æ—Å—Ç—å={analysis_result.is_valuable_dialogue}, –ª–∏–¥–æ–≤={len(analysis_result.potential_leads)}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞: {e}")
            return self._simple_dialogue_analysis(dialogue)

    def _create_dialogue_analysis_prompt(self, dialogue: DialogueContext) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞"""
        participants_info = []
        for user_id, participant in dialogue.participants.items():
            info = f"""
–£—á–∞—Å—Ç–Ω–∏–∫ {participant.first_name} (@{participant.username or '–±–µ–∑_username'}):
- –†–æ–ª—å: {participant.role}
- –°–æ–æ–±—â–µ–Ω–∏–π: {participant.message_count}
- –ü–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã: {participant.buying_signals_count}
- –£—Ä–æ–≤–µ–Ω—å –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏: {participant.engagement_level}"""
            participants_info.append(info)
        
        messages_history = []
        for msg in dialogue.messages:
            timestamp = msg.timestamp.strftime("%H:%M")
            username = msg.username or f"user_{msg.user_id}"
            messages_history.append(f"[{timestamp}] {username}: {msg.text}")
        
        return f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∏–∞–ª–æ–≥–æ–≤ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ —Å—Ñ–µ—Ä–µ IT, CRM —Å–∏—Å—Ç–µ–º –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å–∞.

–ö–û–ù–¢–ï–ö–°–¢ –î–ò–ê–õ–û–ì–ê:
- –ö–∞–Ω–∞–ª: {dialogue.channel_title}
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {(dialogue.last_activity - dialogue.start_time).total_seconds() / 60:.1f} –º–∏–Ω—É—Ç
- –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {len(dialogue.participants)}
- –°–æ–æ–±—â–µ–Ω–∏–π: {len(dialogue.messages)}
- –ë–∏–∑–Ω–µ—Å-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {dialogue.is_business_related}

–£–ß–ê–°–¢–ù–ò–ö–ò:
{''.join(participants_info)}

–ò–°–¢–û–†–ò–Ø –î–ò–ê–õ–û–ì–ê:
{chr(10).join(messages_history)}

–ó–ê–î–ê–ß–ê:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –¥–∏–∞–ª–æ–≥ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:
1. –ï—Å—Ç—å –ª–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã —Å—Ä–µ–¥–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
2. –ì—Ä—É–ø–ø–æ–≤—É—é –¥–∏–Ω–∞–º–∏–∫—É –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
3. –í–ª–∏—è–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞
4. –°–∫—Ä—ã—Ç—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–∞–∂–¥—ã–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–º

–í–ï–†–ù–ò –†–ï–ó–£–õ–¨–¢–ê–¢ –í JSON –§–û–†–ú–ê–¢–ï:
{{
    "is_valuable_dialogue": boolean,
    "confidence_score": number (0-100),
    "business_relevance_score": number (0-100),
    "potential_leads": [
        {{
            "user_id": number,
            "lead_probability": number (0-100),
            "lead_quality": "hot|warm|cold",
            "key_signals": ["—Å–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤"],
            "recommended_approach": "—Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–±–æ—Ç—ã",
            "urgency_level": "immediate|high|medium|low",
            "estimated_budget": "–ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏–ª–∏ null",
            "decision_influencers": [—Å–ø–∏—Å–æ–∫ user_id –≤–ª–∏—è—é—â–∏—Ö –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ],
            "role_in_decision": "decision_maker|influencer|observer|budget_holder"
        }}
    ],
    "group_dynamics": {{
        "decision_making_style": "individual|consensus|leader_driven|committee",
        "dominant_participants": [user_id],
        "influence_relationships": {{user_id: [influenced_user_ids]}},
        "group_sentiment": "positive|negative|neutral|mixed",
        "discussion_stage": "problem_identification|solution_research|vendor_evaluation|decision_pending"
    }},
    "dialogue_summary": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—É—Ç–∏ –¥–∏–∞–ª–æ–≥–∞",
    "key_insights": ["–∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –æ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–æ–º –ø–æ–≤–µ–¥–µ–Ω–∏–∏"],
    "recommended_actions": ["–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"],
    "next_best_action": "—Å–ª–µ–¥—É—é—â–∏–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥",
    "estimated_timeline": "–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è –∏–ª–∏ null",
    "group_budget_estimate": "–æ—Ü–µ–Ω–∫–∞ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –±—é–¥–∂–µ—Ç–∞ –∏–ª–∏ null",
    "buying_probability": {{user_id: probability_0_to_1}},
    "topic_classification": "price_inquiry|feature_discussion|competitor_comparison|implementation_planning|support_request|other"
}}"""

    def _parse_dialogue_analysis_response(self, response_text: str, dialogue: DialogueContext) -> DialogueAnalysisResult:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ AI –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞"""
        try:
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if not json_match:
                raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
            
            data = json.loads(json_match.group())
            
            participant_analysis = {}
            buying_probability = {}
            influence_map = {}
            
            for lead_data in data.get('potential_leads', []):
                user_id = lead_data['user_id']
                participant_analysis[user_id] = {
                    'lead_probability': lead_data.get('lead_probability', 0),
                    'lead_quality': lead_data.get('lead_quality', 'cold'),
                    'key_signals': lead_data.get('key_signals', []),
                    'recommended_approach': lead_data.get('recommended_approach', ''),
                    'role_in_decision': lead_data.get('role_in_decision', 'observer')
                }
                buying_probability[user_id] = lead_data.get('lead_probability', 0) / 100.0
            
            influence_relationships = data.get('group_dynamics', {}).get('influence_relationships', {})
            for influencer_str, influenced_list in influence_relationships.items():
                try:
                    influencer_id = int(influencer_str)
                    influence_map[influencer_id] = [int(uid) for uid in influenced_list]
                except (ValueError, TypeError):
                    continue
            
            return DialogueAnalysisResult(
                dialogue_id=dialogue.dialogue_id,
                is_valuable_dialogue=data.get('is_valuable_dialogue', False),
                confidence_score=data.get('confidence_score', 0),
                potential_leads=data.get('potential_leads', []),
                group_dynamics=data.get('group_dynamics', {}),
                business_relevance_score=data.get('business_relevance_score', 0),
                recommended_actions=data.get('recommended_actions', []),
                key_insights=data.get('key_insights', []),
                dialogue_summary=data.get('dialogue_summary', ''),
                participant_analysis=participant_analysis,
                buying_probability=buying_probability,
                influence_map=influence_map,
                next_best_action=data.get('next_best_action', ''),
                estimated_timeline=data.get('estimated_timeline'),
                group_budget_estimate=data.get('group_budget_estimate')
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞: {e}")
            return self._create_fallback_analysis(dialogue)

    def _simple_dialogue_analysis(self, dialogue: DialogueContext) -> DialogueAnalysisResult:
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ –±–µ–∑ AI"""
        potential_leads = []
        buying_probability = {}
        
        for user_id, participant in dialogue.participants.items():
            score = min(100, participant.buying_signals_count * 25 + participant.message_count * 5)
            
            if score >= 50:
                lead_quality = "hot" if score >= 80 else "warm"
                potential_leads.append({
                    'user_id': user_id,
                    'lead_probability': score,
                    'lead_quality': lead_quality,
                    'key_signals': [f"–ü–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã: {participant.buying_signals_count}"],
                    'recommended_approach': "–°–≤—è–∑–∞—Ç—å—Å—è –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è",
                    'role_in_decision': participant.role
                })
            
            buying_probability[user_id] = score / 100.0
        
        return DialogueAnalysisResult(
            dialogue_id=dialogue.dialogue_id,
            is_valuable_dialogue=len(potential_leads) > 0,
            confidence_score=70 if potential_leads else 30,
            potential_leads=potential_leads,
            group_dynamics={"decision_making_style": "unknown"},
            business_relevance_score=80 if dialogue.is_business_related else 20,
            recommended_actions=["–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"],
            key_insights=["–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ AI"],
            dialogue_summary=f"–î–∏–∞–ª–æ–≥ —Å {len(dialogue.participants)} —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏",
            participant_analysis={},
            buying_probability=buying_probability,
            influence_map={},
            next_best_action="–°–≤—è–∑–∞—Ç—å—Å—è —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º–∏ –ª–∏–¥–∞–º–∏",
            estimated_timeline=None,
            group_budget_estimate=None
        )

    def _create_fallback_analysis(self, dialogue: DialogueContext) -> DialogueAnalysisResult:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return DialogueAnalysisResult(
            dialogue_id=dialogue.dialogue_id,
            is_valuable_dialogue=False,
            confidence_score=0,
            potential_leads=[],
            group_dynamics={},
            business_relevance_score=0,
            recommended_actions=["–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è"],
            key_insights=[],
            dialogue_summary="–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞",
            participant_analysis={},
            buying_probability={},
            influence_map={},
            next_best_action="–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑",
            estimated_timeline=None,
            group_budget_estimate=None
        )

class IntegratedAIContextParser:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AI –ø–∞—Ä—Å–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–æ–≤ –∏ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    
    def __init__(self, config):
        self.config = config
        self.parsing_config = config.get('parsing', {})
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.enabled = self.parsing_config.get('enabled', True)
        self.channels = self._parse_channels()
        self.min_confidence_score = self.parsing_config.get('min_confidence_score', 70)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.context_window_hours = self.parsing_config.get('context_window_hours', 24)
        self.min_messages_for_analysis = self.parsing_config.get('min_messages_for_analysis', 1)
        self.max_context_messages = self.parsing_config.get('max_context_messages', 10)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–æ–≤
        self.dialogue_analysis_enabled = self.parsing_config.get('dialogue_analysis_enabled', True)
        self.prefer_dialogue_analysis = self.parsing_config.get('prefer_dialogue_analysis', True)
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.dialogue_tracker = DialogueTracker(config) if self.dialogue_analysis_enabled else None
        self.dialogue_analyzer = DialogueAnalyzer(config) if self.dialogue_analysis_enabled else None
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.user_contexts: Dict[int, UserContext] = {}
        self.analysis_cache: Dict[str, AIAnalysisResult] = {}
        self.processed_leads: Dict[int, datetime] = {}
        
        logger.info(f"IntegratedAIContextParser –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        logger.info(f"  - –ö–∞–Ω–∞–ª–æ–≤: {len(self.channels)}")
        logger.info(f"  - –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤: {self.dialogue_analysis_enabled}")
        logger.info(f"  - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–∏–∞–ª–æ–≥–∞–º: {self.prefer_dialogue_analysis}")
        logger.info(f"  - –ú–∏–Ω. —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {self.min_confidence_score}%")

    def _parse_channels(self) -> List[str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        channels_raw = self.parsing_config.get('channels', [])
        if isinstance(channels_raw, list):
            return [str(ch) for ch in channels_raw]
        elif isinstance(channels_raw, (str, int)):
            return [str(channels_raw)]
        return []

    async def process_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        try:
            if not self.enabled:
                logger.info("‚ùå AI –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∫–ª—é—á–µ–Ω")
                return
            
            chat_id = update.effective_chat.id
            user = update.effective_user
            message = update.message
            
            if not user or not message or not message.text:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞")
                return
            
            logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è:")
            logger.info(f"    üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user.first_name} (@{user.username})")
            logger.info(f"    üí¨ –¢–µ–∫—Å—Ç: '{message.text[:50]}...'")
            logger.info(f"    üìç –ö–∞–Ω–∞–ª: {chat_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞–Ω–∞–ª –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è
            if not self.is_channel_monitored(chat_id, update.effective_chat.username):
                logger.info("‚è≠Ô∏è –ö–∞–Ω–∞–ª –Ω–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è")
                return
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü—Ä–æ–±—É–µ–º –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            dialogue_processed = False
            if self.dialogue_analysis_enabled and self.dialogue_tracker:
                dialogue_id = await self.dialogue_tracker.process_message(update, context)
                
                if dialogue_id:
                    logger.info(f"üìù –°–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ –¥–∏–∞–ª–æ–≥–µ: {dialogue_id}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∏
                    await self._check_and_analyze_dialogues(context)
                    dialogue_processed = True
                    
                    # –ï—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–∏–∞–ª–æ–≥–∞–º - –Ω–µ –¥–µ–ª–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                    if self.prefer_dialogue_analysis:
                        logger.info("üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–∏–∞–ª–æ–≥–∞–º - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                        return
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –¥–∏–∞–ª–æ–≥ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏–ª–∏ –Ω–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ–Ω)
            if not dialogue_processed or not self.prefer_dialogue_analysis:
                logger.info("üë§ –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
                await self._process_individual_message(update, context)
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º AI –ø–∞—Ä—Å–µ—Ä–µ: {e}")
            import traceback
            traceback.print_exc()

    async def _check_and_analyze_dialogues(self, context: ContextTypes.DEFAULT_TYPE):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤"""
        if not self.dialogue_analysis_enabled or not self.dialogue_analyzer:
            return
        
        try:
            completed_dialogues = self.dialogue_tracker.get_completed_dialogues_for_analysis()
            
            for dialogue in completed_dialogues:
                logger.info(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥: {dialogue.dialogue_id}")
                
                analysis_result = await self.dialogue_analyzer.analyze_dialogue(dialogue)
                
                if analysis_result and analysis_result.is_valuable_dialogue:
                    await self._process_dialogue_analysis_result(dialogue, analysis_result, context)
                    
                    # –ü–æ–º–µ—á–∞–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤ –¥–∏–∞–ª–æ–≥–µ
                    for participant_id in dialogue.participants.keys():
                        self.processed_leads[participant_id] = datetime.now()
                
                # –£–¥–∞–ª—è–µ–º –¥–∏–∞–ª–æ–≥ –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞
                if dialogue.dialogue_id in self.dialogue_tracker.active_dialogues:
                    del self.dialogue_tracker.active_dialogues[dialogue.dialogue_id]
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–æ–≤: {e}")

    async def _process_dialogue_analysis_result(self, dialogue: DialogueContext, 
                                              analysis: DialogueAnalysisResult, 
                                              context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞"""
        try:
            logger.info(f"üíé –¶–µ–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω: {dialogue.dialogue_id}")
            logger.info(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence_score}%")
            logger.info(f"   –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ª–∏–¥–æ–≤: {len(analysis.potential_leads)}")
            
            # –°–æ–∑–¥–∞–µ–º –ª–∏–¥—ã –¥–ª—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
            created_leads = []
            for lead_data in analysis.potential_leads:
                if lead_data['lead_probability'] >= self.min_confidence_score:
                    user_id = lead_data['user_id']
                    participant = dialogue.participants.get(user_id)
                    
                    if participant:
                        lead = await self._create_lead_from_dialogue_participant(
                            participant, dialogue, lead_data, analysis
                        )
                        if lead:
                            created_leads.append((participant, lead_data))
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∞–º –æ —Ü–µ–Ω–Ω–æ–º –¥–∏–∞–ª–æ–≥–µ
            min_confidence_for_notification = self.parsing_config.get('min_dialogue_confidence', 75)
            if (analysis.confidence_score >= min_confidence_for_notification or created_leads):
                await self._notify_admins_about_dialogue(context, dialogue, analysis, created_leads)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–Ω–∞–ª–∞
            await self._update_channel_stats(str(dialogue.channel_id), 
                                           dialogue.messages[-1].message_id if dialogue.messages else 0,
                                           len(created_leads) > 0)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞: {e}")

    async def _process_individual_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        try:
            user = update.effective_user
            message = update.message
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            await self._update_user_context(user, message, update.effective_chat)
            logger.info("‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω")
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_context = self.user_contexts.get(user.id)
            if not user_context:
                logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
                return
            
            logger.info(f"üìä –ö–æ–Ω—Ç–µ–∫—Å—Ç: {len(user_context.messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –∞–Ω–∞–ª–∏–∑—É
            if not self._should_analyze_user(user_context):
                logger.info(f"‚è≥ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.id} –Ω–µ –≥–æ—Ç–æ–≤ –∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É")
                return
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –ª–∏ –Ω–µ–¥–∞–≤–Ω–æ
            if self._was_recently_analyzed(user.id):
                logger.info(f"üîÑ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.id} –Ω–µ–¥–∞–≤–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è")
                return
            
            logger.info("ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑...")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º AI –∞–Ω–∞–ª–∏–∑
            analysis = await self._analyze_user_context(user_context)
            
            if analysis:
                logger.info(f"‚úÖ –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω:")
                logger.info(f"    üéØ –õ–∏–¥: {analysis.is_lead}")
                logger.info(f"    üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence_score}%")
                logger.info(f"    üî• –ö–∞—á–µ—Å—Ç–≤–æ: {analysis.lead_quality}")
                
                if analysis.is_lead and analysis.confidence_score >= self.min_confidence_score:
                    logger.info("üéØ –°–û–ó–î–ê–ï–ú –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–û–ì–û –õ–ò–î–ê!")
                    
                    # –°–æ–∑–¥–∞–µ–º –ª–∏–¥
                    await self._create_lead_from_individual_analysis(user_context, analysis, context)
                    
                    # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, —á—Ç–æ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏
                    self.processed_leads[user.id] = datetime.now()
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–Ω–∞–ª–∞
                    await self._update_channel_stats(str(update.effective_chat.id), 
                                                   message.message_id, True)
                else:
                    logger.info(f"‚ùå –ù–µ –ª–∏–¥: score={analysis.confidence_score}, min={self.min_confidence_score}")
                    await self._update_channel_stats(str(update.effective_chat.id), 
                                                   message.message_id, False)
            else:
                logger.warning("‚ùå –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è")
                await self._update_channel_stats(str(update.effective_chat.id), 
                                               message.message_id, False)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")

    async def _update_user_context(self, user: User, message, chat):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            user_id = user.id
            current_time = datetime.now()
            
            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if user_id not in self.user_contexts:
                logger.info(f"üÜï –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                self.user_contexts[user_id] = UserContext(
                    user_id=user_id,
                    username=user.username,
                    first_name=user.first_name,
                    last_name=user.last_name,
                    messages=[],
                    first_seen=current_time,
                    last_activity=current_time,
                    channel_info={
                        'id': chat.id,
                        'title': chat.title,
                        'username': chat.username,
                        'type': chat.type
                    }
                )
            
            user_context = self.user_contexts[user_id]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            message_data = {
                'text': message.text,
                'date': message.date.isoformat() if message.date else current_time.isoformat(),
                'message_id': message.message_id,
                'timestamp': current_time.isoformat()
            }
            
            user_context.messages.append(message_data)
            user_context.last_activity = current_time
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_context.username = user.username
            user_context.first_name = user.first_name
            user_context.last_name = user.last_name
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            if len(user_context.messages) > self.max_context_messages:
                user_context.messages = user_context.messages[-self.max_context_messages:]
            
            logger.info(f"üìù –î–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. –í—Å–µ–≥–æ: {len(user_context.messages)}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.id}: {e}")

    def _should_analyze_user(self, user_context: UserContext) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –≥–æ—Ç–æ–≤ –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É"""
        messages_count = len(user_context.messages)
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π
        if messages_count < self.min_messages_for_analysis:
            logger.info(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {messages_count} < {self.min_messages_for_analysis}")
            return False
        
        # –î–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–ª—å–Ω—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã
        if messages_count == 1:
            first_message = user_context.messages[0]['text'].lower()
            strong_signals = self._has_strong_buying_signals(first_message)
            
            if strong_signals:
                logger.info(f"üî• –°–ò–õ–¨–ù–´–ï –ü–û–ö–£–ü–ê–¢–ï–õ–¨–°–ö–ò–ï –°–ò–ì–ù–ê–õ–´ –≤ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏!")
                return True
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ - –∂–¥–µ–º –≤—Ä–µ–º—è –∏–ª–∏ –µ—â–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            time_since_last = datetime.now() - user_context.last_activity
            if time_since_last > timedelta(minutes=2):
                logger.info(f"‚úÖ –ü—Ä–æ—à–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {time_since_last}")
                return True
            
            logger.info(f"‚è≥ –û–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤, –∂–¥–µ–º: {time_since_last} < 2 –º–∏–Ω")
            return False
        
        # –î–ª—è 2+ —Å–æ–æ–±—â–µ–Ω–∏–π - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–∞–∑—É
        if messages_count >= 2:
            logger.info(f"‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {messages_count}")
            return True
        
        return False

    def _has_strong_buying_signals(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–ª—å–Ω—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ"""
        strong_signals = [
            '—Ö–æ—á—É –∫—É–ø–∏—Ç—å', '—Ö–æ—á—É –∑–∞–∫–∞–∑–∞—Ç—å', '–≥–æ—Ç–æ–≤ –∫—É–ø–∏—Ç—å', '–≥–æ—Ç–æ–≤ –∑–∞–∫–∞–∑–∞—Ç—å',
            '–Ω—É–∂–Ω–æ –∫—É–ø–∏—Ç—å', '–ø–ª–∞–Ω–∏—Ä—É—é –∫—É–ø–∏—Ç—å', '—Å–æ–±–∏—Ä–∞—é—Å—å –∫—É–ø–∏—Ç—å',
            '—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç', '–∫–∞–∫–∞—è —Ü–µ–Ω–∞', '–∫–∞–∫–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ü–µ–Ω–∞ –∑–∞',
            '—Å—Ç–æ–∏–º–æ—Å—Ç—å —É—Å–ª—É–≥', '–ø—Ä–∞–π—Å-–ª–∏—Å—Ç', '–ø—Ä–∞–π—Å –ª–∏—Å—Ç', '—Ä–∞—Å—Ü–µ–Ω–∫–∏',
            '—Å—Ä–æ—á–Ω–æ –Ω—É–∂–Ω–æ', '–Ω—É–∂–Ω–æ —Å–µ–≥–æ–¥–Ω—è', '–Ω—É–∂–Ω–æ —Å–µ–π—á–∞—Å', '–∫–∞–∫ –º–æ–∂–Ω–æ –±—ã—Å—Ç—Ä–µ–µ',
            '–∑–∞–∫–∞–∑–∞—Ç—å –±–æ—Ç–∞', '—Å–¥–µ–ª–∞—Ç—å –±–æ—Ç–∞', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –±–æ—Ç–∞', '—Å–æ–∑–¥–∞—Ç—å –±–æ—Ç–∞',
            '–Ω—É–∂–µ–Ω –±–æ—Ç', '–∏—â—É —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞', '–Ω—É–∂–Ω–∞ crm', '–∑–∞–∫–∞–∑–∞—Ç—å crm',
            '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∏–∑–Ω–µ—Å', '–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é',
            '–æ–±—Å—É–¥–∏—Ç—å –ø—Ä–æ–µ–∫—Ç', '–æ–±—Å—É–¥–∏—Ç—å —É—Å–ª–æ–≤–∏—è', '–æ–±—Å—É–¥–∏—Ç—å –¥–µ—Ç–∞–ª–∏',
            '—Å–≤—è–∑–∞—Ç—å—Å—è —Å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º', '–ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å –æ —Ü–µ–Ω–µ'
        ]
        
        for signal in strong_signals:
            if signal in text:
                logger.info(f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω —Å–∏–ª—å–Ω—ã–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª: '{signal}'")
                return True
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å–ª–æ–≤
        buying_words = ['–∫—É–ø–∏—Ç—å', '–∑–∞–∫–∞–∑–∞—Ç—å', '–Ω—É–∂–Ω–æ', '–Ω—É–∂–µ–Ω', '–Ω—É–∂–Ω–∞', '—Ö–æ—á—É', '–∏—â—É']
        service_words = ['–±–æ—Ç', 'crm', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü', '–∏–Ω—Ç–µ–≥—Ä–∞—Ü', '—Ä–∞–∑—Ä–∞–±–æ—Ç', '—Å–∏—Å—Ç–µ–º']
        
        buying_found = any(word in text for word in buying_words)
        service_found = any(word in text for word in service_words)
        
        if buying_found and service_found:
            logger.info(f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –≤ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏: –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–æ–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ + –Ω–∞—à–∏ —É—Å–ª—É–≥–∏")
            return True
        
        return False

    def _was_recently_analyzed(self, user_id: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ–¥–∞–≤–Ω–æ"""
        if user_id in self.processed_leads:
            last_analysis = self.processed_leads[user_id]
            time_diff = datetime.now() - last_analysis
            if time_diff < timedelta(hours=self.context_window_hours):
                logger.info(f"üîÑ –ù–µ–¥–∞–≤–Ω–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {time_diff} –Ω–∞–∑–∞–¥")
                return True
        return False

    async def _analyze_user_context(self, user_context: UserContext) -> Optional[AIAnalysisResult]:
        """AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            logger.info("ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑...")
            
            claude_client = get_claude_client()
            if not claude_client or not claude_client.client:
                logger.warning("‚ùå Claude API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                return self._simple_analysis(user_context)
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –∫—ç—à–∞
            messages_text = " | ".join([msg['text'] for msg in user_context.messages[-5:]])
            cache_key = f"individual_{user_context.user_id}:{hash(messages_text)}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            if cache_key in self.analysis_cache:
                logger.info(f"üíæ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è {user_context.user_id}")
                return self.analysis_cache[cache_key]
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            context_data = self._prepare_context_for_ai(user_context)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Claude
            analysis_prompt = self._create_individual_analysis_prompt(context_data)
            
            logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≤ Claude...")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Claude —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            try:
                response = await asyncio.wait_for(
                    claude_client.client.messages.create(
                        model=claude_client.model,
                        max_tokens=2000,
                        messages=[{"role": "user", "content": analysis_prompt}],
                        temperature=0.1
                    ),
                    timeout=15.0
                )
                
                logger.info("üì• –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Claude –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                analysis_result = self._parse_individual_ai_response(response.content[0].text)
                
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                self.analysis_cache[cache_key] = analysis_result
                
                logger.info(f"‚úÖ –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–µ–Ω: –ª–∏–¥={analysis_result.is_lead}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={analysis_result.confidence_score}%")
                
                return analysis_result
                
            except asyncio.TimeoutError:
                logger.warning("‚è∞ –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–≤—ã—Å–∏–ª —Ç–∞–π–º–∞—É—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑")
                return self._simple_analysis(user_context)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return self._simple_analysis(user_context)

    def _simple_analysis(self, user_context: UserContext) -> AIAnalysisResult:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ AI"""
        logger.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        all_text = " ".join([msg['text'] for msg in user_context.messages]).lower()
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        high_interest = ['–∫—É–ø–∏—Ç—å', '–∑–∞–∫–∞–∑–∞—Ç—å', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç', 'crm', '–±–æ—Ç', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è']
        medium_interest = ['–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ', '–ø–æ–¥—Ä–æ–±–Ω–µ–µ', '—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ', '–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç']
        
        score = 0
        interests = []
        buying_signals = []
        
        for word in high_interest:
            if word in all_text:
                score += 30
                interests.append(word)
                if word in ['–∫—É–ø–∏—Ç—å', '–∑–∞–∫–∞–∑–∞—Ç—å', '—Ü–µ–Ω–∞']:
                    buying_signals.append(f"–£–ø–æ–º–∏–Ω–∞–Ω–∏–µ '{word}'")
        
        for word in medium_interest:
            if word in all_text:
                score += 15
                interests.append(word)
        
        score = min(100, score)
        is_lead = score >= 60
        
        if is_lead:
            lead_quality = "hot" if score >= 80 else "warm"
        else:
            lead_quality = "cold"
        
        result = AIAnalysisResult(
            is_lead=is_lead,
            confidence_score=score,
            lead_quality=lead_quality,
            interests=interests,
            buying_signals=buying_signals,
            urgency_level="medium" if score >= 70 else "low",
            recommended_action="–°–≤—è–∑–∞—Ç—å—Å—è —Å –∫–ª–∏–µ–Ω—Ç–æ–º" if is_lead else "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ",
            key_insights=[f"–ü—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–ª score {score}"],
            estimated_budget=None,
            timeline=None,
            pain_points=[],
            decision_stage="consideration" if is_lead else "awareness"
        )
        
        logger.info(f"üîß –ü—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: score={score}, –ª–∏–¥={is_lead}")
        return result

    def _prepare_context_for_ai(self, user_context: UserContext) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞"""
        return {
            'user': {
                'id': user_context.user_id,
                'username': user_context.username,
                'first_name': user_context.first_name,
                'last_name': user_context.last_name,
                'first_seen': user_context.first_seen.isoformat(),
                'last_activity': user_context.last_activity.isoformat()
            },
            'messages': user_context.messages,
            'channel': user_context.channel_info,
            'messages_count': len(user_context.messages),
            'activity_span_hours': (user_context.last_activity - user_context.first_seen).total_seconds() / 3600
        }

    def _create_individual_analysis_prompt(self, context_data: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞"""
        
        messages_text = "\n".join([
            f"[{msg.get('date', 'unknown')}] {msg['text']}" 
            for msg in context_data['messages']
        ])
        
        return f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ —Å—Ñ–µ—Ä–µ IT-—É—Å–ª—É–≥, CRM —Å–∏—Å—Ç–µ–º, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å–∞ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ Telegram –±–æ—Ç–æ–≤.

–ö–û–ù–¢–ï–ö–°–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
- –ò–º—è: {context_data['user']['first_name']} (@{context_data['user']['username']})
- –ö–∞–Ω–∞–ª: {context_data['channel']['title']} ({context_data['channel']['type']})
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {context_data['messages_count']}
- –ü–µ—Ä–∏–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {context_data['activity_span_hours']:.1f} —á–∞—Å–æ–≤

–°–û–û–ë–©–ï–ù–ò–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{messages_text}

–ó–ê–î–ê–ß–ê:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–ï —Å–æ–æ–±—â–µ–Ω–∏—è —ç—Ç–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–Ω –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–æ–º –¥–ª—è —É—Å–ª—É–≥:
- CRM —Å–∏—Å—Ç–µ–º –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å–∞
- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∏ Telegram –±–æ—Ç–æ–≤
- IT-–∫–æ–Ω—Å–∞–ª—Ç–∏–Ω–≥–∞ –∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π –∏ API —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

–í–ï–†–ù–ò –†–ï–ó–£–õ–¨–¢–ê–¢ –°–¢–†–û–ì–û –í JSON –§–û–†–ú–ê–¢–ï:
{{
    "is_lead": boolean,
    "confidence_score": number (0-100),
    "lead_quality": "hot|warm|cold|not_lead",
    "interests": ["—Å–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤"],
    "buying_signals": ["—Å–∏–≥–Ω–∞–ª—ã –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"],
    "urgency_level": "immediate|short_term|long_term|none",
    "recommended_action": "—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ",
    "key_insights": ["–∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã"],
    "estimated_budget": "–ø—Ä–∏–º–µ—Ä–Ω—ã–π –±—é–¥–∂–µ—Ç –∏–ª–∏ null",
    "timeline": "–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏ –∏–ª–∏ null",
    "pain_points": ["–ø—Ä–æ–±–ª–µ–º—ã –∫–ª–∏–µ–Ω—Ç–∞"],
    "decision_stage": "awareness|consideration|decision|post_purchase"
}}

–û–ë–†–ê–¢–ò–¢–ï –û–°–û–ë–û–ï –í–ù–ò–ú–ê–ù–ò–ï:
- –ü—Ä—è–º—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã (—Ö–æ—á—É –∫—É–ø–∏—Ç—å, —Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç, –Ω—É–∂–Ω–æ –∑–∞–∫–∞–∑–∞—Ç—å) = –ì–û–†–Ø–ß–ò–ô –õ–ò–î
- –û–¥–∏–Ω–æ—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Å–∏–ª—å–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏ –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∞—Ç—å –≤—ã—Å–æ–∫–∏–π confidence_score (85-95)
- –°—Ä–æ—á–Ω–æ—Å—Ç—å –≤ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–≤—ã—à–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç

–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
- is_lead: true –µ—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞ –∫ –Ω–∞—à–∏–º —É—Å–ª—É–≥–∞–º
- confidence_score: 90-100 = –æ—á–µ–≤–∏–¥–Ω—ã–π –∫–ª–∏–µ–Ω—Ç, 70-89 = –≤–µ—Ä–æ—è—Ç–Ω—ã–π, 50-69 = –≤–æ–∑–º–æ–∂–Ω—ã–π, <50 = –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω—ã–π
- lead_quality: hot = –≥–æ—Ç–æ–≤ –ø–æ–∫—É–ø–∞—Ç—å, warm = –∏–∑—É—á–∞–µ—Ç —Ä—ã–Ω–æ–∫, cold = —Ç–æ–ª—å–∫–æ –Ω–∞—á–∏–Ω–∞–µ—Ç –ø–æ–∏—Å–∫
- urgency_level: –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å—Ä–æ—á–Ω–æ –Ω—É–∂–Ω–æ —Ä–µ—à–µ–Ω–∏–µ

–í–ê–ñ–ù–û:
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –í–ï–°–¨ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ò—â–∏ —Å–∫—Ä—ã—Ç—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –∏ –ø–æ–¥—Ç–µ–∫—Å—Ç
- –û–±—Ä–∞—â–∞–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç
- –í—ã—Å–æ–∫–∏–π confidence_score —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —è–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–∞—Ö
- –ë—É–¥—å –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–º, –Ω–µ –∑–∞–≤—ã—à–∞–π –æ—Ü–µ–Ω–∫–∏"""

    def _parse_individual_ai_response(self, response_text: str) -> AIAnalysisResult:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            logger.info(f"üìã –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ AI: {response_text[:200]}...")
            
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if not json_match:
                logger.warning("‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ AI")
                raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ AI")
            
            json_str = json_match.group()
            data = json.loads(json_str)
            
            logger.info(f"‚úÖ JSON –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: is_lead={data.get('is_lead')}, score={data.get('confidence_score')}")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            return AIAnalysisResult(
                is_lead=bool(data.get('is_lead', False)),
                confidence_score=max(0, min(100, int(data.get('confidence_score', 0)))),
                lead_quality=data.get('lead_quality', 'not_lead'),
                interests=data.get('interests', []),
                buying_signals=data.get('buying_signals', []),
                urgency_level=data.get('urgency_level', 'none'),
                recommended_action=data.get('recommended_action', ''),
                key_insights=data.get('key_insights', []),
                estimated_budget=data.get('estimated_budget'),
                timeline=data.get('timeline'),
                pain_points=data.get('pain_points', []),
                decision_stage=data.get('decision_stage', 'awareness')
            )
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ AI: {e}")
            logger.debug(f"–û—Ç–≤–µ—Ç AI: {response_text}")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return AIAnalysisResult(
                is_lead=False,
                confidence_score=0,
                lead_quality='not_lead',
                interests=[],
                buying_signals=[],
                urgency_level='none',
                recommended_action='–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è',
                key_insights=[],
                estimated_budget=None,
                timeline=None,
                pain_points=[],
                decision_stage='awareness'
            )

    async def _create_lead_from_dialogue_participant(self, participant, dialogue, lead_data, analysis):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ª–∏–¥–∞ –∏–∑ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –¥–∏–∞–ª–æ–≥–∞"""
        try:
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–∞
            participant_messages = [
                msg.text for msg in dialogue.messages 
                if msg.user_id == participant.user_id
            ]
            
            lead = Lead(
                telegram_id=participant.user_id,
                username=participant.username,
                first_name=participant.first_name,
                last_name=participant.last_name,
                source_channel=f"{dialogue.channel_title} (–¥–∏–∞–ª–æ–≥)",
                interest_score=lead_data['lead_probability'],
                message_text=" | ".join(participant_messages),
                message_date=dialogue.last_activity,
                
                # AI –ø–æ–ª—è –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞
                lead_quality=lead_data['lead_quality'],
                interests=json.dumps(lead_data.get('key_signals', []), ensure_ascii=False),
                buying_signals=json.dumps(lead_data.get('key_signals', []), ensure_ascii=False),
                urgency_level=lead_data.get('urgency_level', 'medium'),
                estimated_budget=analysis.group_budget_estimate,
                timeline=analysis.estimated_timeline,
                pain_points=json.dumps(analysis.key_insights, ensure_ascii=False),
                decision_stage=dialogue.decision_stage,
                notes=f"–î–∏–∞–ª–æ–≥ {dialogue.dialogue_id}. –†–æ–ª—å: {lead_data.get('role_in_decision', '—É—á–∞—Å—Ç–Ω–∏–∫')}. {lead_data.get('recommended_approach', '')}"
            )
            
            await create_lead(lead)
            logger.info(f"‚úÖ –õ–∏–¥ —Å–æ–∑–¥–∞–Ω –∏–∑ –¥–∏–∞–ª–æ–≥–∞: {participant.first_name} ({participant.user_id})")
            return lead
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ª–∏–¥–∞ –∏–∑ –¥–∏–∞–ª–æ–≥–∞: {e}")
            return None

    async def _create_lead_from_individual_analysis(self, user_context: UserContext, 
                                                  analysis: AIAnalysisResult, 
                                                  context: ContextTypes.DEFAULT_TYPE):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ª–∏–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            logger.info("üéØ –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –ª–∏–¥–∞ –∏–∑ AI –∞–Ω–∞–ª–∏–∑–∞...")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            all_messages = " | ".join([msg['text'] for msg in user_context.messages])
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ª–∏–¥–∞
            lead = Lead(
                telegram_id=user_context.user_id,
                username=user_context.username,
                first_name=user_context.first_name,
                last_name=user_context.last_name,
                source_channel=user_context.channel_info['title'] or str(user_context.channel_info['id']),
                interest_score=analysis.confidence_score,
                message_text=all_messages,
                message_date=user_context.last_activity,
                
                # AI –ø–æ–ª—è
                lead_quality=analysis.lead_quality,
                interests=json.dumps(analysis.interests, ensure_ascii=False),
                buying_signals=json.dumps(analysis.buying_signals, ensure_ascii=False),
                urgency_level=analysis.urgency_level,
                estimated_budget=analysis.estimated_budget,
                timeline=analysis.timeline,
                pain_points=json.dumps(analysis.pain_points, ensure_ascii=False),
                decision_stage=analysis.decision_stage,
                notes="–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ AI"
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
            await create_lead(lead)
            
            logger.info(f"‚úÖ –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–ô AI –õ–ò–î –°–û–ó–î–ê–ù: {user_context.first_name} (@{user_context.username})")
            logger.info(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {analysis.lead_quality}")
            logger.info(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence_score}%")
            logger.info(f"   –ò–Ω—Ç–µ—Ä–µ—Å—ã: {', '.join(analysis.interests)}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∞–º
            await self._notify_admins_about_individual_lead(context, user_context, analysis)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –ª–∏–¥–∞: {e}")
            import traceback
            traceback.print_exc()

    async def _notify_admins_about_individual_lead(self, context: ContextTypes.DEFAULT_TYPE, 
                                                 user_context: UserContext, 
                                                 analysis: AIAnalysisResult):
        """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–æ–≤ –æ –Ω–æ–≤–æ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º AI –ª–∏–¥–µ"""
        try:
            admin_ids = self.config.get('bot', {}).get('admin_ids', [])
            if not admin_ids:
                logger.warning("‚ùå –ù–µ—Ç –∞–¥–º–∏–Ω–æ–≤ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º –ª–∏–¥–µ")
                return
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏ —ç–º–æ–¥–∑–∏
            priority_config = {
                'hot': {'emoji': 'üî•üî•üî•', 'text': '–ì–û–†–Ø–ß–ò–ô –õ–ò–î', 'color': 'üü•'},
                'warm': {'emoji': 'üî•üî•', 'text': '–¢–ï–ü–õ–´–ô –õ–ò–î', 'color': 'üü®'},
                'cold': {'emoji': 'üî•', 'text': '–•–û–õ–û–î–ù–´–ô –õ–ò–î', 'color': 'üü¶'}
            }
            
            priority = priority_config.get(analysis.lead_quality, 
                                         {'emoji': '‚≠ê', 'text': '–ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ô –õ–ò–î', 'color': '‚¨ú'})
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏
            interests_text = ', '.join(analysis.interests) if analysis.interests else '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã'
            pain_points_text = '\n‚Ä¢ '.join(analysis.pain_points) if analysis.pain_points else '–Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã'
            buying_signals_text = '\n‚Ä¢ '.join(analysis.buying_signals) if analysis.buying_signals else '–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã'
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            username_text = f"@{user_context.username}" if user_context.username else "–±–µ–∑ username"
            
            message = f"""{priority['emoji']} <b>{priority['text']}</b> {priority['color']}

üë§ <b>–ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–ô AI –ê–ù–ê–õ–ò–ó</b>

üë§ <b>–ö–æ–Ω—Ç–∞–∫—Ç:</b> {user_context.first_name} ({username_text})
üÜî <b>ID:</b> <code>{user_context.user_id}</code>
üéØ <b>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</b> {analysis.confidence_score}% 
üìä <b>–ö–∞—á–µ—Å—Ç–≤–æ:</b> {analysis.lead_quality.upper()}
üì∫ <b>–ò—Å—Ç–æ—á–Ω–∏–∫:</b> {user_context.channel_info['title']}
üí¨ <b>–°–æ–æ–±—â–µ–Ω–∏–π:</b> {len(user_context.messages)}
‚è∞ <b>–ü–µ—Ä–∏–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:</b> {(user_context.last_activity - user_context.first_seen).total_seconds() / 3600:.1f}—á

üé™ <b>–ò–Ω—Ç–µ—Ä–µ—Å—ã:</b> {interests_text}

üö© <b>–ë–æ–ª–µ–≤—ã–µ —Ç–æ—á–∫–∏:</b>
‚Ä¢ {pain_points_text}

üí∞ <b>–ü–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã:</b>
‚Ä¢ {buying_signals_text}

‚ö° <b>–°—Ä–æ—á–Ω–æ—Å—Ç—å:</b> {analysis.urgency_level}
üíµ <b>–ë—é–¥–∂–µ—Ç:</b> {analysis.estimated_budget or '–Ω–µ —É–∫–∞–∑–∞–Ω'}
üìÖ <b>–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏:</b> {analysis.timeline or '–Ω–µ —É–∫–∞–∑–∞–Ω—ã'}
üé≠ <b>–°—Ç–∞–¥–∏—è —Ä–µ—à–µ–Ω–∏—è:</b> {analysis.decision_stage}

üéØ <b>–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ:</b>
<i>{analysis.recommended_action}</i>

üîç <b>–ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:</b>
{chr(10).join([f"‚Ä¢ {insight}" for insight in analysis.key_insights])}

üîó <b>–°–≤—è–∑–∞—Ç—å—Å—è:</b> <a href="tg://user?id={user_context.user_id}">–û—Ç–∫—Ä—ã—Ç—å –¥–∏–∞–ª–æ–≥</a>"""

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ–º –∞–¥–º–∏–Ω–∞–º
            successful_notifications = 0
            for admin_id in admin_ids:
                try:
                    await context.bot.send_message(
                        chat_id=admin_id,
                        text=message,
                        parse_mode='HTML',
                        disable_web_page_preview=True
                    )
                    successful_notifications += 1
                except Exception as e:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º –ª–∏–¥–µ –∞–¥–º–∏–Ω—É {admin_id}: {e}")
            
            logger.info(f"‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º –ª–∏–¥–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã {successful_notifications}/{len(admin_ids)} –∞–¥–º–∏–Ω–∞–º")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ–± –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º –ª–∏–¥–µ: {e}")

    async def _notify_admins_about_dialogue(self, context: ContextTypes.DEFAULT_TYPE,
                                          dialogue, analysis, created_leads):
        """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–æ–≤ –æ —Ü–µ–Ω–Ω–æ–º –¥–∏–∞–ª–æ–≥–µ"""
        try:
            admin_ids = self.config.get('bot', {}).get('admin_ids', [])
            if not admin_ids:
                return
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            if analysis.confidence_score >= 90:
                priority_emoji = "üî•üî•üî•"
                priority_text = "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ô –î–ò–ê–õ–û–ì"
            elif analysis.confidence_score >= 80:
                priority_emoji = "üî•üî•"
                priority_text = "–í–´–°–û–ö–û–ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ô –î–ò–ê–õ–û–ì"
            else:
                priority_emoji = "üî•"
                priority_text = "–í–ê–ñ–ù–´–ô –î–ò–ê–õ–û–ì"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—á–∞—Å—Ç–Ω–∏–∫–∞—Ö
            participants_info = []
            for user_id, participant in dialogue.participants.items():
                buying_prob = analysis.buying_probability.get(user_id, 0)
                emoji = "üéØ" if buying_prob >= 0.7 else "üë§"
                username = f"@{participant.username}" if participant.username else f"ID{user_id}"
                participants_info.append(f"{emoji} {participant.first_name} ({username}) - {buying_prob*100:.0f}%")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ª–∏–¥–∞—Ö
            leads_info = ""
            if created_leads:
                leads_info = f"\nüéØ <b>–°–æ–∑–¥–∞–Ω—ã –ª–∏–¥—ã:</b>\n"
                for participant, lead_data in created_leads:
                    username = f"@{participant.username}" if participant.username else "–±–µ–∑ username"
                    leads_info += f"‚Ä¢ {participant.first_name} ({username}) - {lead_data['lead_quality']}\n"
            
            message = f"""{priority_emoji} <b>{priority_text}</b>

ü§ñ <b>AI –ê–ù–ê–õ–ò–ó –ì–†–£–ü–ü–û–í–û–ì–û –î–ò–ê–õ–û–ì–ê</b>

üì∫ <b>–ö–∞–Ω–∞–ª:</b> {dialogue.channel_title}
üïê <b>–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:</b> {(dialogue.last_activity - dialogue.start_time).total_seconds() / 60:.0f} –º–∏–Ω
üë• <b>–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤:</b> {len(dialogue.participants)}
üí¨ <b>–°–æ–æ–±—â–µ–Ω–∏–π:</b> {len(dialogue.messages)}
üìä <b>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</b> {analysis.confidence_score}%
üè¢ <b>–ë–∏–∑–Ω–µ—Å-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å:</b> {analysis.business_relevance_score}%

üìã <b>–°—É—Ç—å –¥–∏–∞–ª–æ–≥–∞:</b>
<i>{analysis.dialogue_summary}</i>

üë• <b>–ê–Ω–∞–ª–∏–∑ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤:</b>
{chr(10).join(participants_info)}

üß† <b>–ì—Ä—É–ø–ø–æ–≤–∞—è –¥–∏–Ω–∞–º–∏–∫–∞:</b>
‚Ä¢ –°—Ç–∏–ª—å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π: {analysis.group_dynamics.get('decision_making_style', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}
‚Ä¢ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≥—Ä—É–ø–ø—ã: {analysis.group_dynamics.get('group_sentiment', '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è')}
‚Ä¢ –°—Ç–∞–¥–∏—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è: {analysis.group_dynamics.get('discussion_stage', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')}

üí° <b>–ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:</b>
{chr(10).join([f"‚Ä¢ {insight}" for insight in analysis.key_insights])}

üéØ <b>–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:</b>
{chr(10).join([f"‚Ä¢ {action}" for action in analysis.recommended_actions])}

‚ö° <b>–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:</b> {analysis.next_best_action}
üìÖ <b>–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏:</b> {analysis.estimated_timeline or '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã'}
üí∞ <b>–ë—é–¥–∂–µ—Ç –≥—Ä—É–ø–ø—ã:</b> {analysis.group_budget_estimate or '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'}{leads_info}

üîó <b>–£—á–∞—Å—Ç–Ω–∏–∫–∏ –¥–∏–∞–ª–æ–≥–∞:</b>
{chr(10).join([f"<a href='tg://user?id={uid}'>–ù–∞–ø–∏—Å–∞—Ç—å {p.first_name}</a>" for uid, p in dialogue.participants.items()])}"""

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ–º –∞–¥–º–∏–Ω–∞–º
            for admin_id in admin_ids:
                try:
                    await context.bot.send_message(
                        chat_id=admin_id,
                        text=message,
                        parse_mode='HTML',
                        disable_web_page_preview=True
                    )
                except Exception as e:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –¥–∏–∞–ª–æ–≥–µ –∞–¥–º–∏–Ω—É {admin_id}: {e}")
            
            logger.info(f"‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –¥–∏–∞–ª–æ–≥–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –∞–¥–º–∏–Ω–∞–º")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ –¥–∏–∞–ª–æ–≥–µ: {e}")

    async def _update_channel_stats(self, channel_id: str, message_id: int, lead_found: bool):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞–Ω–∞–ª–∞"""
        try:
            leads_count = 1 if lead_found else 0
            await update_channel_stats(channel_id, message_id, leads_count)
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {channel_id}, –ª–∏–¥={lead_found}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

    def is_channel_monitored(self, chat_id: int, chat_username: str = None) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞"""
        if not self.enabled:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ ID
        if str(chat_id) in self.channels:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ username
        if chat_username:
            username_variants = [f"@{chat_username}", chat_username]
            for variant in username_variants:
                if variant in self.channels:
                    return True
        
        return False

    def get_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞"""
        status = {
            'enabled': self.enabled,
            'channels_count': len(self.channels),
            'channels': self.channels,
            'min_confidence_score': self.min_confidence_score,
            'context_window_hours': self.context_window_hours,
            'individual_active_users': len(self.user_contexts),
            'individual_analysis_cache_size': len(self.analysis_cache),
            'individual_processed_leads_count': len(self.processed_leads),
            'dialogue_analysis_enabled': self.dialogue_analysis_enabled,
            'prefer_dialogue_analysis': self.prefer_dialogue_analysis
        }
        
        if self.dialogue_tracker:
            status['dialogue_tracker'] = {
                'active_dialogues': len(self.dialogue_tracker.active_dialogues),
                'min_participants': self.dialogue_tracker.min_participants,
                'min_messages': self.dialogue_tracker.min_messages,
                'dialogue_timeout_minutes': self.dialogue_tracker.dialogue_timeout.total_seconds() / 60
            }
        
        return status

# –ê–ª–∏–∞—Å—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
AIContextParser = IntegratedAIContextParser

__all__ = [
    'IntegratedAIContextParser',
    'AIContextParser',
    'DialogueTracker',
    'DialogueAnalyzer',
    'DialogueContext',
    'DialogueParticipant',
    'DialogueMessage',
    'DialogueAnalysisResult',
    'AIAnalysisResult',
    'UserContext'
]